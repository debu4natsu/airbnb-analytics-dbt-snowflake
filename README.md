
# ğŸ  Airbnb Data Platform â€“ End-to-End ELT with Snowflake & dbt

## ğŸ“Œ Overview

This project implements a production-style, end-to-end data platform for Airbnb analytics using **Snowflake**, **dbt**, and **AWS S3**. The pipeline follows a **Medallion architecture** and demonstrates:

- Incremental data processing
- Slowly Changing Dimensions (SCD Type 2)
- Metadata-driven modeling
- Modular transformation design
- Layered schema isolation
- Automated lineage and testing

The system transforms raw CSV data into analytics-ready datasets optimized for BI and downstream consumption.

---

## ğŸ— Architecture

```
CSV â†’ AWS S3 â†’ Snowflake (Staging)
                      â†“
               Bronze Layer (Raw)
                      â†“
              Silver Layer (Cleansed)
                      â†“
               Gold Layer (Analytics)
```

**Core Principles**
- ELT-based transformation
- Incremental-first processing strategy
- Layer isolation via schema management
- Reusable macro-driven transformations
- Snapshot-based historical tracking

---

## ğŸ›  Technology Stack

| Component | Technology |
|---|---|
| Cloud Data Warehouse | Snowflake |
| Transformation Engine | dbt (Core) |
| Cloud Storage | AWS S3 |
| Templating Engine | Jinja |
| Language | SQL + Python |
| Version Control | Git |

---

## ğŸ“Š Data Modeling Approach

### ğŸ¥‰ Bronze Layer
- Raw ingestion from staging
- Incremental materialization
- Minimal transformation
- **Schema:** `AIRBNB.BRONZE`

### ğŸ¥ˆ Silver Layer
- Business logic & cleansing
- Derived metrics
- Reusable macro logic
- **Schema:** `AIRBNB.SILVER`

### ğŸ¥‡ Gold Layer
- Analytics-ready models
- Fact + dimensional structures
- Metadata-driven join generation
- **Schema:** `AIRBNB.GOLD`

---

## ğŸ” Incremental Processing Strategy

Models use timestamp-based filtering to avoid full refresh:

```sql
{{ config(materialized='incremental') }}

{% if is_incremental() %}
  WHERE CREATED_AT > (SELECT COALESCE(MAX(CREATED_AT), '1900-01-01') FROM {{ this }})
{% endif %}
```

This design:
- Minimizes compute cost
- Reduces full-table scans
- Improves scalability for growing datasets

---

## ğŸ§  Snapshot Strategy (SCD Type 2)

Implemented timestamp-based snapshots to:
- Preserve historical record versions
- Enable point-in-time analytics
- Maintain `valid_from` / `valid_to` tracking
- Avoid destructive updates

---

## âš™ï¸ Metadata-Driven Modeling

Gold OBT model uses configuration-driven joins:
- Dynamic SQL generation via Jinja loops
- Reduced hardcoding
- Centralized join definitions
- Improved maintainability

---

## ğŸ”„ Custom Macros

Reusable logic implemented via dbt macros:

| Macro | Purpose |
|---|---|
| `multiply()` | Controlled precision calculations |
| `tag()` | Dynamic price categorization |
| `generate_schema_name()` | Custom schema resolution |
| `trimmer()` | Standardized string formatting |

---

## ğŸ§ª Data Quality & Governance

- Source validation tests
- Unique and not-null constraints
- Snapshot consistency checks
- Automatic lineage tracking via `dbt docs`

---

## ğŸš€ Running the Project

```bash
dbt debug      # Validate configuration
dbt run        # Execute models
dbt test       # Run tests
dbt snapshot   # Execute SCD logic
dbt docs serve # View lineage graph
```

---

## ğŸ” Engineering Best Practices

- Schema isolation by data layer
- Incremental-first design philosophy
- Environment-driven materialization
- Credentials excluded from version control
- Role-based access control in Snowflake

---

## ğŸ“ˆ Future Enhancements

- [ ] CI/CD integration
- [ ] Automated data quality monitoring
- [ ] BI integration (Tableau / Power BI)
- [ ] Data observability & alerting
- [ ] Performance benchmarking
